<?xml version="1.0" encoding="UTF-8"?>
<SunopsisExport>
<Admin RepositoryVersion="05.02.02.05" IsLegacyIdCompatible="false" />
<Encryption algorithm="AES" keyLength="128" exportKeyHash="" keyVect="dm5R54syn4r4adWriAEqmA==" exportKeySalt="f507eef1-57c6-46df-bd31-988838316c08" containsCipherText="false"/>
<Object class="com.sunopsis.dwg.dbobj.SnpTrt">
		<Field name="CleanupOnError" type="java.lang.String">null</Field>
	<Field name="CompType" type="java.lang.String"><![CDATA[AP]]></Field>
	<Field name="DelegateClass" type="java.lang.String"><![CDATA[LKMSparkHDFS]]></Field>
	<Field name="DelegateScript" type="java.lang.String"><![CDATA[
        import com.sunopsis.tools.core.SnpsStringTools;
	import oracle.odi.mapping.generation.AbstractSyntaxTree.ASTProducerMethod;
	import oracle.odi.domain.mapping.generator.KMGeneratorDelegateRegistry.GeneratorDelegateClass;
	@GeneratorDelegateClass(componentType="AP", descriptionKey="GeneratorDelegateClass.LKMSparkHDFS")
	public class LKMSparkHDFS extends LKMSpark {
		static { 
	            LKMSpark.storageClasses.put(LKMSparkJsonHDFSLoader.LOADER_FUNCTION,LKMSparkJsonHDFSLoader.class);
	            LKMSpark.storageClasses.put(LKMSparkParquetLoader.LOADER_FUNCTION,LKMSparkParquetLoader.class);
	            LKMSpark.storageClasses.put(LKMSparkNewHadoopFileLoader.LOADER_FUNCTION,LKMSparkNewHadoopFileLoader.class); 
	            LKMSpark.storageClasses.put(LKMSparkDelimitedLoader.LOADER_FUNCTION,LKMSparkDelimitedLoader.class);
              LKMSpark.storageClasses.put(LKMSparkJsonHDFSStore.STORAGE_FUNCTION,LKMSparkJsonHDFSStore.class);
	             LKMSpark.storageClasses.put(LKMSparkAVROHDFSStore.STORAGE_FUNCTION,LKMSparkAVROHDFSStore.class);
	             LKMSpark.storageClasses.put(LKMSparkPARQUETHDFSStore.STORAGE_FUNCTION,LKMSparkPARQUETHDFSStore.class);
	             LKMSpark.storageClasses.put(LKMSparkDelimitedLoader.STORAGE_FUNCTION,LKMSparkDelimitedLoader.class);
	             
              
	        }
		
		static class LKMSparkJsonHDFSLoader extends LKMSpark.LKMSparkStorage { 
		    static final String LOADER_FUNCTION = "json"; 
		    @Override
		    String getLoaderFunction() {
		        return LOADER_FUNCTION;
		    } 
		} 
		
		static class LKMSparkParquetLoader extends LKMSpark.LKMSparkStorage { 
		    static final String LOADER_FUNCTION = "parquet"; 
		    @Override
		    String getLoaderFunction() {
		        return LOADER_FUNCTION;
		    } 
		}
			static class LKMSparkHadoopLoader extends LKMSpark.LKMSparkStorage { 

		    @Override
		    void addCommand(SparkCommand command) {
		       storageCommand = command;
		    }   
		    
		   	@Override
		    String handleFunctionParam(LKMSpark.FunctionParam param,
		                             String value,
		                             boolean isLoader) throws AdapterException,
		                                          oracle.odi.domain.mapping.exception.MappingException {
		        if (param.name.equals("Job Configuration") && (value == null || value == "None" || value == "")) {
		            if (storageCommand !=null && storageCommand instanceof SparkLoadCmd){
		            	String rowSep = ((SparkLoadCmd)storageCommand).getRowSep();
		            	if (rowSep != null && rowSep != ""){
		            			return "{\"textinputformat.record.delimiter\":\""+ rowSep + "\"}";
		            		}
		            }
		        } else if ((param.name.equals(LKMSpark.LKMSparkStorage.PARAM_KEY_CLASS) 
		        		|| param.name.equals(LKMSpark.LKMSparkStorage.PARAM_VALUE_CLASS)
		        		|| param.name.equals(LKMSpark.LKMSparkStorage.PARAM_KEY_CONVERTER) 
		        		|| param.name.equals(LKMSpark.LKMSparkStorage.PARAM_VALUE_CONVERTER)
		        		|| param.name.equals(LKMSpark.LKMSparkStorage.PARAM_OUTPUT_FORMAT)
		        		|| param.name.equals(LKMSpark.LKMSparkStorage.PARAM_INPUT_FORMAT))
		        	  && value != "None" && value != null && value != "")		{
								value = "'" + value + "'";		        	
		        }      		        		        
		        return value;
		    }    
		}

			static class LKMSparkHadoopStorer extends LKMSpark.LKMSparkStorage { 

		    @Override
		    void addCommand(SparkCommand command) {
		       storageCommand = command;
		    }   
		    
		   	@Override
		    String handleFunctionParam(LKMSpark.FunctionParam param,
		                             String value,
		                             boolean isLoader) throws AdapterException,
		                                          oracle.odi.domain.mapping.exception.MappingException {
						if ((param.name.equals(LKMSpark.LKMSparkStorage.PARAM_KEY_CLASS) 
		        		|| param.name.equals(LKMSpark.LKMSparkStorage.PARAM_VALUE_CLASS)
		        		|| param.name.equals(LKMSpark.LKMSparkStorage.PARAM_KEY_CONVERTER) 
		        		|| param.name.equals(LKMSpark.LKMSparkStorage.PARAM_VALUE_CONVERTER)
		        		|| param.name.equals(LKMSpark.LKMSparkStorage.PARAM_OUTPUT_FORMAT)
		        		|| param.name.equals(LKMSpark.LKMSparkStorage.PARAM_INPUT_FORMAT))
		        	  && value != "None" && value != null && value != "")		{
								value = "'" + value + "'";		        	
		        }      		        		        
		        return value;
		    }    
		}

		static class LKMSparkNewHadoopFileLoader extends LKMSparkHadoopLoader { 
		    static final String LOADER_FUNCTION = "newAPIHadoopFile"; 
		    static List<LKMSpark.FunctionParam> FUNCT_ARG = new ArrayList<LKMSpark.FunctionParam>();
		    
		    static {
		        FUNCT_ARG.add(new LKMSpark.FunctionParam(LKMSpark.LKMSparkStorage.PARAM_INPUT_FORMAT));
		        FUNCT_ARG.add(new LKMSpark.FunctionParam(LKMSpark.LKMSparkStorage.PARAM_KEY_CLASS));
		        FUNCT_ARG.add(new LKMSpark.FunctionParam(LKMSpark.LKMSparkStorage.PARAM_VALUE_CLASS));
		        FUNCT_ARG.add(new LKMSpark.FunctionParam(LKMSpark.LKMSparkStorage.PARAM_KEY_CONVERTER));
		        FUNCT_ARG.add(new LKMSpark.FunctionParam(LKMSpark.LKMSparkStorage.PARAM_VALUE_CONVERTER));
		        FUNCT_ARG.add(new LKMSpark.FunctionParam(LKMSpark.LKMSparkStorage.PARAM_CONF_NAME));		          
		    }
		    
		    @Override
		    String getLoaderFunction() {
		        return LOADER_FUNCTION;
		    } 
		    
		   	@Override
		    List<LKMSpark.FunctionParam> getLoaderFunctionParams() {
		        return FUNCT_ARG;
		    }
		}
		 


	static class LKMSparkJsonHDFSStore extends LKMSpark.LKMSparkStorage { 
		    static final String STORAGE_FUNCTION = "json"; 
		    @Override
		    String getLoaderFunction() {
		        return STORAGE_FUNCTION;
		    }
		
		    @Override
		    String getStorerFunction() {
		  	  return STORAGE_FUNCTION;
		    } 
		}
		
static class LKMSparkAVROHDFSStore extends LKMSpark.LKMSparkStorage { 
		    static final String STORAGE_FUNCTION = "com.databricks.spark.avro"; 
		    @Override
		    String getLoaderFunction() {
		        return STORAGE_FUNCTION;
		    }
		
		    @Override
		    String getStorerFunction() {
		  	  return STORAGE_FUNCTION;
		    } 
		}
		static class LKMSparkPARQUETHDFSStore extends LKMSpark.LKMSparkStorage { 
		    static final String STORAGE_FUNCTION = "parquet"; 
		    @Override
		    String getLoaderFunction() {
		        return STORAGE_FUNCTION;
		    }
		
		    @Override
		    String getStorerFunction() {
		  	  return STORAGE_FUNCTION;
		    } 
		}
		
		static class LKMSparkDelimitedLoader extends LKMSpark.LKMSparkStorage { 
		    static final String LOADER_FUNCTION = "com.databricks.spark.csv"; 
		    static final String STORAGE_FUNCTION = "com.databricks.spark.csv";
		    @Override
		    String getLoaderFunction() {
		        return LOADER_FUNCTION;
		    }
		    		
		    @Override
		    String getStorerFunction() {
		  	  return STORAGE_FUNCTION;
		    }  	    

		}
		
		         String getDelimDataStoreStorageValue(MapPhysicalNode physicalNode) throws AdapterException, oracle.odi.domain.mapping.exception.MappingException {
                  oracle.odi.domain.model.OdiDataStore dataStore = (oracle.odi.domain.model.OdiDataStore)physicalNode.getLogicalComponent().getBoundObject();
                  StringBuilder strBuilder = new StringBuilder();
                  
                  String fieldSeparator = dataStore.getHadoopStorageDescriptor().getFieldSeparator();
                  String textDelimiter = dataStore.getHadoopStorageDescriptor().getTextDelimiter();
                  int headerLines = dataStore.getHadoopStorageDescriptor().getSkipHeadingLines();
                  strBuilder.append("options(");
                  if (headerLines > 0 ) {
                      strBuilder.append("header='true', inferSchema='true'");
                      }else{
                      strBuilder.append("header='false', inferSchema='false'");
                      }
                  if(fieldSeparator != null || textDelimiter != null ){
                  strBuilder.append(",delimiter=");
                      if (textDelimiter != null) {
                      strBuilder.append("'");
                      strBuilder.append(textDelimiter);
                      strBuilder.append("'");
                      }else{
                      if(fieldSeparator.equalsIgnoreCase("0x09") || fieldSeparator.equalsIgnoreCase('\\u0009')){
                      strBuilder.append("'\\t'");
                      }else{
                      strBuilder.append("'");
                      strBuilder.append(fieldSeparator);
                      strBuilder.append("'");
                      }
                      }
                      }
                      
                      strBuilder.append(")");
                      return strBuilder.toString();
                   throw new RuntimeException("Unknown FlexField : "+flexFieldName);
                }
		
				    

	@ASTProducerMethod(processingType=ProcessingType.SOURCE, producedASTType=SparkScript.class, styleKey="ProcessingStyleKey.Spark.ExtractScript")
 	AbstractSyntaxTree EXTRACT_TAP(SqlQuery sqlQuery) throws AdapterException,
        	                                             oracle.odi.domain.mapping.exception.MappingException,
            	                                         GenerationException {
        	generatorContext.putObject( "mapping.spark.includeJdbcJars", new Boolean( true ) )
        	List<MapPhysicalNode> parentNodes = physicalNode.getUpstreamConnectedNodes();

        	if (parentNodes.size() != 1) {
            	throw new RuntimeException();
        	}

        	MapPhysicalNode parentNode = parentNodes.get(0);
        	Object srcCompBondObj = parentNode.getLogicalComponent().getBoundObject();
        	String techno_type = parentNode.getExecutionTechnology().getInternalName();
        	String storageFn = LKMSpark.LKMSparkStorage.getOptionValue(physicalNode, "Storage Function");
        	String inputFormatClass = LKMSpark.LKMSparkStorage.getOptionValue(physicalNode, "InputFormatClass");
        	String options =getDelimDataStoreStorageValue(parentNode);
        	String storage_FileFormat = null;
        	//should get streaming flag from EU
        	Boolean isStreamingMode = SparkScript.isNodeInStreamingMode(parentNode);
        	if (isStreamingMode) {
            	throw new oracle.odi.domain.mapping.exception.MappingException("Streaming is not supported for 'LKM HDFS to Spark' requires to uncheck Streaming");
        	}
			if ("HDFS".equals(techno_type)){
			storage_FileFormat = (((oracle.odi.domain.model.OdiDataStore) srcCompBondObj).getRealObject()).getHadoopStorageDescriptor().getFormatType().getName().toLowerCase()
        		if ("json".equals(storage_FileFormat))
        		storageFn = "json";
        		else if ("avro".equals(storage_FileFormat)){
        				storageFn = "com.databricks.spark.avro";}
        		else if ("delimited".equals(storage_FileFormat)){
         				storageFn = "com.databricks.spark.csv";}
        		else
        		storageFn = storage_FileFormat;
        		
        	}           	
            if ("textFile".equals(storageFn) && isStreamingMode) {
              storageFn = "textFileStream";
            }
        	if (storageFn.equals("")) {
            	throw new oracle.odi.domain.mapping.exception.MappingException("The option 'Storage Function' requires a value");
        	}
        	
        	String streamingContext = LKMSpark.LKMSparkStorage.getOptionValue(physicalNode, "streamingContext");
            LKMSpark.LKMSparkStorage lkmSpark = getLKMSpark(storageFn);  
            lkmSpark.setPhysicalNodes(physicalNode, parentNode);
            
        	String dataSource = OdiRef.getOdiGeneratedAccessName("SOURCE_NAME", parentNode);
        	
						TemplateUtils templateUtils = getTemplateUtils();
			    		SparkLoadCmd loadCmd = new SparkLoadCmd(templateUtils, parentNode);
			    		if (lkmSpark.getBaseUrl() != null) {
			    		   	dataSource = lkmSpark.getBaseUrl() + dataSource;
			    		}

	
					
					if ("HDFS".equals(techno_type)){        				
        				loadCmd.setTechnology(techno_type);
        				if ("avro".equals(storage_FileFormat)){
        				loadCmd.setFileFormat("AVRO");   
        				} else if ("parquet".equals(storage_FileFormat)){
        				loadCmd.setFileFormat("PARQUET");   
        				} else if ("json".equals(storage_FileFormat)){
        				loadCmd.setFileFormat("JSON");   
        				} else if ("delimited".equals(storage_FileFormat)){
        				loadCmd.setLoadOptions(options);
        				loadCmd.setFieldSep(SnpsStringTools.escapeUnicode(SnpsStringTools.hexStrToStr(SnpsStringTools.replaceNVL(parentNode.getLogicalComponent().getBoundObject().getHadoopStorageDescriptor().getFieldSeparator())),true));    				
        				}      				
					     
        			}    
        				
        		
  
					if ("newAPIHadoopRDD".equals(storageFn))
						loadCmd.setLoadFile(false);
					
					loadCmd.setFlexField("STREAMING_CONTEXT",streamingContext)
			
						
					lkmSpark.addCommand(loadCmd);
					lkmSpark.populateLoaderFunctionParams(loadCmd);
			    loadCmd.setFileLoc(dataSource); 
			
  	
        	SparkScript sparkScript = new SparkScript(templateUtils, null);
        	

        	
        	sparkScript.addChild(loadCmd);
        	return sparkScript;
        
    	}

		@ASTProducerMethod(processingType=ProcessingType.TARGET, producedASTType=SparkScript.class, styleKey="ProcessingStyleKey.Spark.LoadScript")
		AbstractSyntaxTree LOAD_TAP(SparkScript sparkScript) throws AdapterException, oracle.odi.domain.mapping.exception.MappingException, GenerationException {
        	generatorContext.putObject( "mapping.spark.includeJdbcJars", new Boolean( true ) )
        	List<MapPhysicalNode> parentNodes = physicalNode.getUpstreamConnectedNodes();

        	List<MapPhysicalNode> childNodes = physicalNode.getDownstreamConnectedNodes();

        	MapPhysicalNode childNode = childNodes.get(0);
        	String techno_type = childNode.getExecutionTechnology().getInternalName(); 
        	Object tgtCompBondObj = childNode.getLogicalComponent().getBoundObject();
        	String options =getDelimDataStoreStorageValue(childNode);
        	String storage_FileFormat = null;
        	if (parentNodes.size() != 1) {
            	throw new RuntimeException();
        	}
        	
	        String storageFn = LKMSpark.LKMSparkStorage.getOptionValue(physicalNode, "Storage Function");
			String outputFormatClass = LKMSpark.LKMSparkStorage.getOptionValue(physicalNode, "OutputFormatClass");
			storage_FileFormat = (((oracle.odi.domain.model.OdiDataStore) tgtCompBondObj).getRealObject()).getHadoopStorageDescriptor().getFormatType().getName().toLowerCase();
			if ("HDFS".equals(techno_type)){        				
        		if ("json".equals(storage_FileFormat))
        		storageFn = "json"; 
        		else if ("avro".equals(storage_FileFormat))
        		storageFn = "com.databricks.spark.avro";
        		else if ("delimited".equals(storage_FileFormat)){
         				storageFn = "com.databricks.spark.csv";}
        		else
        		storageFn = storage_FileFormat;
        		
        	}    

        	if (storageFn.equals("")) {
            	throw new oracle.odi.domain.mapping.exception.MappingException("The option 'Storage Function' requires a value");
        	}
        	
        	


            LKMSpark.LKMSparkStorage lkmSpark = getLKMSpark(storageFn); 
            lkmSpark.setPhysicalNodes(physicalNode, childNode);

        	MapPhysicalNode parentNode = lkmSpark.getNonAPParentNode(parentNodes.get(0));

        	String outputLocation = OdiRef.getOdiGeneratedAccessName("TARG_NAME", childNode,  "D");
        
        
            if (lkmSpark.getBaseUrl() != null) {
    		   	outputLocation = lkmSpark.getBaseUrl() + outputLocation;
    		}
    		
            SparkStoreCmd storeCmd = new SparkStoreCmd(sparkScript.getTemplateUtils(), childNode);
            storeCmd.setDirectory(outputLocation);
            if ("delimited".equals(storage_FileFormat)){
        				storeCmd.setStoreOptions(options);   
        				}
            lkmSpark.addCommands(storeCmd);
            
        	lkmSpark.populateStorerFunctionParams(storeCmd);
        
        	storeCmd.setTgtAttrExprs(lkmSpark.getMapExpressions(childNode));
        	storeCmd.setTgtAttrNames(lkmSpark.getMapExpressionAliases(childNode));
        	storeCmd.setFullTgtAttrs(childNode.getNodeAttributes());
			 		storeCmd.setTgtDataTypes(lkmSpark.getConvertedTgtDataTypes(childNode,storeCmd.getTemplateUtils().getTechno()));
		  

					if ("HDFS".equals(techno_type)){        				
        				storeCmd.setTechnologyType(techno_type);
        			}
               	
        	
        	List<SparkScript> sparkScripts = new ArrayList<SparkScript>(1);
        	sparkScripts.add(sparkScript);
        	SparkScript storeScript = new SparkScript(sparkScript.getTemplateUtils(), sparkScripts);             
        	storeScript.addChild(storeCmd);
	       	return getLKMStoreScript(storeScript);
    	}
    	@ASTProducerMethod(processingType=ProcessingType.TARGET, producedASTType=NullTarget.class,styleKey="ProcessingStyleKey.Spark.LoadScript")
    	AbstractSyntaxTree PRE_EXTRACT_TAP(SqlQuery input) {
       		NullTarget result = new NullTarget();
        	result.setUpstreamAST(input);
        	return result;
    	}
 
 	}
]]></Field>
	<Field name="ExpectedAstClass" type="java.lang.String">null</Field>
	<Field name="ExtVersion" type="java.lang.String">null</Field>
	<Field name="FirstDate" type="java.sql.Timestamp"><![CDATA[2019-06-10 20:54:14.0]]></Field>
	<Field name="FirstUser" type="java.lang.String"><![CDATA[SUNOPSIS_INSTALL]]></Field>
	<Field name="GlobalId" type="java.lang.String"><![CDATA[33920E0F49656934E053E603C40A3C0A]]></Field>
	<Field name="IndChange" type="java.lang.String"><![CDATA[U]]></Field>
	<Field name="IndGenerateLoad" type="java.lang.String"><![CDATA[1]]></Field>
	<Field name="IndIsHidden" type="java.lang.String"><![CDATA[1]]></Field>
	<Field name="IndJrnMethod" type="java.lang.String">null</Field>
	<Field name="IndSuppSetBased" type="java.lang.String"><![CDATA[0]]></Field>
	<Field name="IntgType" type="java.lang.String">null</Field>
	<Field name="IntVersion" type="com.sunopsis.sql.DbInt"><![CDATA[2]]></Field>
	<Field name="IsConcurrent" type="java.lang.String">null</Field>
	<Field name="IsSeeded" type="java.lang.String"><![CDATA[1]]></Field>
	<Field name="IBaseCompKm" type="com.sunopsis.sql.DbInt"><![CDATA[113]]></Field>
	<Field name="IFolder" type="com.sunopsis.sql.DbInt"><![CDATA[null]]></Field>
	<Field name="IProject" type="com.sunopsis.sql.DbInt"><![CDATA[null]]></Field>
	<Field name="IScBaseTrt" type="com.sunopsis.sql.DbInt"><![CDATA[null]]></Field>
	<Field name="IScOrigTrt" type="com.sunopsis.sql.DbInt"><![CDATA[null]]></Field>
	<Field name="IScTrt" type="com.sunopsis.sql.DbInt"><![CDATA[null]]></Field>
	<Field name="ITrt" type="com.sunopsis.sql.DbInt"><![CDATA[117]]></Field>
	<Field name="ITxtDelTxt" type="com.sunopsis.sql.DbInt"><![CDATA[null]]></Field>
	<Field name="ITxtTrtTxt" type="com.sunopsis.sql.DbInt"><![CDATA[631]]></Field>
	<Field name="KimMultiDserver" type="java.lang.String"><![CDATA[0]]></Field>
	<Field name="KmDefault" type="java.lang.String"><![CDATA[1]]></Field>
	<Field name="KmLang" type="java.lang.String">null</Field>
	<Field name="KmSrcLang" type="java.lang.String"><![CDATA[PYTHON]]></Field>
	<Field name="KmSrcTechno" type="java.lang.String"><![CDATA[SPARK_PYTHON]]></Field>
	<Field name="KmTechno" type="java.lang.String"><![CDATA[HDFS]]></Field>
	<Field name="KmVersion" type="java.lang.String">null</Field>
	<Field name="LastDate" type="java.sql.Timestamp"><![CDATA[2019-06-10 20:54:45.0]]></Field>
	<Field name="LastUser" type="java.lang.String"><![CDATA[SUNOPSIS_INSTALL]]></Field>
	<Field name="LkmType" type="java.lang.String"><![CDATA[N]]></Field>
	<Field name="LChecksum" type="com.sunopsis.sql.DbInt"><![CDATA[0]]></Field>
	<Field name="LCode" type="java.lang.String">null</Field>
	<Field name="OggJkm" type="java.lang.String">null</Field>
	<Field name="OrdFolder" type="com.sunopsis.sql.DbInt"><![CDATA[null]]></Field>
	<Field name="ProcType" type="java.lang.String"><![CDATA[N]]></Field>
	<Field name="ProdAstType" type="java.lang.String">null</Field>
	<Field name="RepGuid" type="java.lang.String">null</Field>
	<Field name="RepVersion" type="java.lang.String">null</Field>
	<Field name="ScriptPath" type="java.lang.String">null</Field>
	<Field name="ScOrigTrtTag" type="java.lang.String">null</Field>
	<Field name="Subtype" type="java.lang.String"><![CDATA[SELECT*]]></Field>
	<Field name="TrtName" type="java.lang.String"><![CDATA[LKMSparkHDFS]]></Field>
	<Field name="TrtType" type="java.lang.String"><![CDATA[CK]]></Field>
	<Field name="VariableDefs" type="java.lang.String">null</Field>
	<Field name="VLastDate" type="java.sql.Timestamp">null</Field>
</Object>
<Object class="com.sunopsis.dwg.dbobj.SnpReferencedObject">
		<Field name="IObject" type="com.sunopsis.sql.DbInt"><![CDATA[3600]]></Field>
	<Field name="ObjectPKasString" type="java.lang.String"><![CDATA[113]]></Field>
	<Field name="ObjectAKasString" type="java.lang.String"><![CDATA[]]></Field>
	<Field name="Description" type="java.lang.String"><![CDATA[SNP_TRT : LKMSpark]]></Field>
 <Field name="GlobalId" type="java.lang.String"><![CDATA[80aa8be2-d68d-40fe-bc1e-0b0b3ee0105e]]></Field>
</Object>
<Object class="com.sunopsis.dwg.dbobj.SnpKmTemplateJoin">
		<Field name="GlobalId" type="java.lang.String"><![CDATA[dda37d1d-6a39-4461-a815-214b4a8b4ecd]]></Field>
	<Field name="ISnpKmTemplate" type="com.sunopsis.sql.DbInt"><![CDATA[87]]></Field>
	<Field name="ISnpTrt" type="com.sunopsis.sql.DbInt"><![CDATA[117]]></Field>
</Object>
<Object class="com.sunopsis.dwg.dbobj.SnpKmTemplateJoin">
		<Field name="GlobalId" type="java.lang.String"><![CDATA[61a389fd-72b3-460a-bbd4-6d47fe144852]]></Field>
	<Field name="ISnpKmTemplate" type="com.sunopsis.sql.DbInt"><![CDATA[89]]></Field>
	<Field name="ISnpTrt" type="com.sunopsis.sql.DbInt"><![CDATA[117]]></Field>
</Object>
<Object class="com.sunopsis.dwg.dbobj.SnpKmTemplateJoin">
		<Field name="GlobalId" type="java.lang.String"><![CDATA[7d5c15e2-0255-4774-b15a-e657eb7b975c]]></Field>
	<Field name="ISnpKmTemplate" type="com.sunopsis.sql.DbInt"><![CDATA[88]]></Field>
	<Field name="ISnpTrt" type="com.sunopsis.sql.DbInt"><![CDATA[117]]></Field>
</Object>
<Object class="com.sunopsis.dwg.dbobj.SnpKmTemplateJoin">
		<Field name="GlobalId" type="java.lang.String"><![CDATA[01eabf79-ddfa-4632-bdcd-16092f0afc68]]></Field>
	<Field name="ISnpKmTemplate" type="com.sunopsis.sql.DbInt"><![CDATA[90]]></Field>
	<Field name="ISnpTrt" type="com.sunopsis.sql.DbInt"><![CDATA[117]]></Field>
</Object>
<Object class="com.sunopsis.dwg.dbobj.SnpTxtHeader">
		<Field name="Enc" type="java.lang.String"><![CDATA[0]]></Field>
	<Field name="EncKey" type="java.lang.String">null</Field>
 <Field name="EncKeyVect" type="java.lang.String">null</Field>
	<Field name="GlobalId" type="java.lang.String"><![CDATA[4228d142-d73f-4f57-86a1-30ef7924ccde]]></Field>
	<Field name="ITxt" type="com.sunopsis.sql.DbInt"><![CDATA[631]]></Field>
	<Field name="ITxtOrig" type="com.sunopsis.sql.DbInt"><![CDATA[107]]></Field>
	<Field name="SqlIndGrp" type="java.lang.String"><![CDATA[0]]></Field>
 <Field name="Txt" type="java.lang.String">null</Field>
</Object>
<Object class="com.sunopsis.dwg.dbobj.SnpOrigTxt">
		<Field name="GlobalId" type="java.lang.String">null</Field>
	<Field name="ITxtOrig" type="com.sunopsis.sql.DbInt"><![CDATA[107]]></Field>
	<Field name="OrigineName" type="java.lang.String"><![CDATA[Edit Command]]></Field>
	<Field name="SnpsCol" type="java.lang.String"><![CDATA[I_TXT_TRT_TXT]]></Field>
	<Field name="SnpsTable" type="java.lang.String"><![CDATA[SNP_TRT]]></Field>
</Object>
<Object class="com.sunopsis.dwg.dbobj.SnpFKXRef">
		<Field name="RefKey" type="java.lang.String"><![CDATA[SNP_TXTHEADER.631]]></Field>
	<Field name="RefObjGlobalId" type="java.lang.String"><![CDATA[4228d142-d73f-4f57-86a1-30ef7924ccde]]></Field>
 <Field name="RefObjFQName" type="java.lang.String">null</Field>
 <Field name="RefObjFQType" type="java.lang.String">null</Field>
 <Field name="RefObjFQNameLengths" type="java.lang.String">null</Field>
</Object>
<Object class="com.sunopsis.dwg.dbobj.SnpFKXRef">
		<Field name="RefKey" type="java.lang.String"><![CDATA[SNP_TRT.113]]></Field>
	<Field name="RefObjGlobalId" type="java.lang.String"><![CDATA[80aa8be2-d68d-40fe-bc1e-0b0b3ee0105e]]></Field>
 <Field name="RefObjFQName" type="java.lang.String"><![CDATA[LKMSpark]]></Field>
 <Field name="RefObjFQType" type="java.lang.String"><![CDATA[SNP_TRT]]></Field>
 <Field name="RefObjFQNameLengths" type="java.lang.String"><![CDATA[8]]></Field>
</Object>
<Object class="com.sunopsis.dwg.dbobj.SnpFKXRef">
		<Field name="RefKey" type="java.lang.String"><![CDATA[SNP_TRT.117]]></Field>
	<Field name="RefObjGlobalId" type="java.lang.String"><![CDATA[33920E0F49656934E053E603C40A3C0A]]></Field>
 <Field name="RefObjFQName" type="java.lang.String"><![CDATA[LKMSparkHDFS]]></Field>
 <Field name="RefObjFQType" type="java.lang.String"><![CDATA[SNP_TRT]]></Field>
 <Field name="RefObjFQNameLengths" type="java.lang.String"><![CDATA[12]]></Field>
</Object>
<Object class="com.sunopsis.dwg.dbobj.SnpFKXRef">
		<Field name="RefKey" type="java.lang.String"><![CDATA[SNP_KMTEMPLATE.87]]></Field>
	<Field name="RefObjGlobalId" type="java.lang.String"><![CDATA[fa46e05a-2d00-11e6-93fa-00163e1ffd72]]></Field>
 <Field name="RefObjFQName" type="java.lang.String"><![CDATA[SparkPythonSubmit]]></Field>
 <Field name="RefObjFQType" type="java.lang.String"><![CDATA[SNP_KMTEMPLATE]]></Field>
 <Field name="RefObjFQNameLengths" type="java.lang.String"><![CDATA[17]]></Field>
</Object>
<Object class="com.sunopsis.dwg.dbobj.SnpFKXRef">
		<Field name="RefKey" type="java.lang.String"><![CDATA[SNP_KMTEMPLATE.89]]></Field>
	<Field name="RefObjGlobalId" type="java.lang.String"><![CDATA[fa46e082-2d00-11e6-93fb-00163e1ffd72]]></Field>
 <Field name="RefObjFQName" type="java.lang.String"><![CDATA[SparkPythonSubmitSync]]></Field>
 <Field name="RefObjFQType" type="java.lang.String"><![CDATA[SNP_KMTEMPLATE]]></Field>
 <Field name="RefObjFQNameLengths" type="java.lang.String"><![CDATA[21]]></Field>
</Object>
<Object class="com.sunopsis.dwg.dbobj.SnpFKXRef">
		<Field name="RefKey" type="java.lang.String"><![CDATA[SNP_KMTEMPLATE.88]]></Field>
	<Field name="RefObjGlobalId" type="java.lang.String"><![CDATA[bcb3a042-a6d7-11e6-ac06-23e5aaa09e30]]></Field>
 <Field name="RefObjFQName" type="java.lang.String"><![CDATA[SparkPythonSubmitCommon]]></Field>
 <Field name="RefObjFQType" type="java.lang.String"><![CDATA[SNP_KMTEMPLATE]]></Field>
 <Field name="RefObjFQNameLengths" type="java.lang.String"><![CDATA[23]]></Field>
</Object>
<Object class="com.sunopsis.dwg.dbobj.SnpFKXRef">
		<Field name="RefKey" type="java.lang.String"><![CDATA[SNP_KMTEMPLATE.90]]></Field>
	<Field name="RefObjGlobalId" type="java.lang.String"><![CDATA[fa46e0aa-2d00-11e6-93fc-00163e1ffd72]]></Field>
 <Field name="RefObjFQName" type="java.lang.String"><![CDATA[SparkPythonSubmitAsync]]></Field>
 <Field name="RefObjFQType" type="java.lang.String"><![CDATA[SNP_KMTEMPLATE]]></Field>
 <Field name="RefObjFQNameLengths" type="java.lang.String"><![CDATA[22]]></Field>
</Object>
<Object class="com.sunopsis.dwg.DwgExportSummary">
		<Field name="ExpTxtNb" type="com.sunopsis.sql.DbInt"><![CDATA[0]]></Field>
	<Field name="InstObjNb" type="com.sunopsis.sql.DbInt"><![CDATA[0]]></Field>
	<Field name="JoinColNb" type="com.sunopsis.sql.DbInt"><![CDATA[0]]></Field>
	<Field name="JoinNb" type="com.sunopsis.sql.DbInt"><![CDATA[0]]></Field>
	<Field name="KeyColNb" type="com.sunopsis.sql.DbInt"><![CDATA[0]]></Field>
	<Field name="KeyNb" type="com.sunopsis.sql.DbInt"><![CDATA[0]]></Field>
	<Field name="LinkDiagNb" type="com.sunopsis.sql.DbInt"><![CDATA[0]]></Field>
	<Field name="MorigTxtNb" type="com.sunopsis.sql.DbInt"><![CDATA[0]]></Field>
	<Field name="MtxtNb" type="com.sunopsis.sql.DbInt"><![CDATA[0]]></Field>
	<Field name="OrigTxtNb" type="com.sunopsis.sql.DbInt"><![CDATA[1]]></Field>
	<Field name="OtherObjectsNb" type="com.sunopsis.sql.DbInt"><![CDATA[5]]></Field>
	<Field name="PlanAgentNb" type="com.sunopsis.sql.DbInt"><![CDATA[0]]></Field>
	<Field name="StepNb" type="com.sunopsis.sql.DbInt"><![CDATA[0]]></Field>
	<Field name="TxtNb" type="com.sunopsis.sql.DbInt"><![CDATA[1]]></Field>
	<Field name="UeOrigNb" type="com.sunopsis.sql.DbInt"><![CDATA[0]]></Field>
	<Field name="UeUsedNb" type="com.sunopsis.sql.DbInt"><![CDATA[0]]></Field>
	<Field name="VarPlanAgentNb" type="com.sunopsis.sql.DbInt"><![CDATA[0]]></Field>
	<Field name="ScenTxtNb" type="com.sunopsis.sql.DbInt"><![CDATA[0]]></Field>
	<Field name="OdiVersion" type="java.lang.String"><![CDATA[12.2.1]]></Field>
	<Field name="OriginRepositoryID" type="com.sunopsis.sql.DbInt"><![CDATA[1]]></Field>
	<Field name="RepositoryVersion" type="java.lang.String"><![CDATA[05.02.02.05]]></Field>
</Object>
</SunopsisExport>
